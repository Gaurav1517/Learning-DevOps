############## Ansible ###################

Ansible network configure in ansible-controller & workers 

# All machine should ping each other either in same network or another . 

#check ip of the system both machine
hostname -i 
ifconfig
ifconfig ens160

# # local dns-entry in /etc/hosts file in both machine
cat <<EOF>> /etc/hosts

192.168.157.150 ansible-controller
192.168.157.149 ansible-worker01
EOF

# set hostname of system
controller:
hostnamectl set-hostname ansible-controller
worker01:
hostnamectl set-hostname ansible-worker01

# refresh terminal in both machine
bash

# ping with ip & hostname in both machine
 ping -c 4 192.168.157.150 && \
 ping -c 4 ansible-controller
 ping -c 4 192.168.157.149 && \
 ping -c 4 ansible-worker01


#To check the status of various network interfaces on system on ansible controller.
nmcli show connection 
# Create new connection for ansible-controller
nmcli connection add \
 con-name ansible-controller \
 ifname ens160 \
 type ethernet \
 autoconnect yes
# connection up 
nmcli connection up ansible-controller
# verify network interface
nmcli show connection 
# delete older connection ((optional))
nmcli delete connection <older-connection>

#To check the status of various network interfaces on system on ansible worker01.
nmcli show connection 
# Create new connection for ansible-worker01
nmcli connection add \
 con-name ansible-worker01 \
 ifname ens160 \
 type ethernet \
 autoconnect yes
# connection up 
nmcli connection up ansible-worker01
# verify network interface
nmcli show connection 
# delete older connection ((optional))
nmcli delete connection <older-connection>

# Create connection with ssh . 

Ansible is agent-less because ssh is already installed in OS. 
# Check openssh package available on ansible-controller & and all worker nodes
yum list installed openssh
rpm -qa | grep openssh-server

# Install Ansible
REF: https://docs.ansible.com/ansible/2.9/installation_guide/intro_installation.html

### Step 1: Install EPEL repository
yum install epel-release -y
### Step 2: Install Python 3.9 and pip
dnf install python39 python39-pip -y
### Step 3: Install Ansible using Python 3.9's pip
python3.9 -m pip install ansible
### Step 4: Verify Ansible Installation
ansible --version
ansible [core 2.15.13]
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.9/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.9.6 (default, Aug 25 2021, 16:22:38) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)] (/usr/bin/python3.9)
  jinja version = 3.1.6
  libyaml = True


Firstly we need to create configuration file of ansible .

# crate directory 
mkdir -p /etc/ansible/

cat <<EOF > /etc/ansible/ansible.cfg
[defaults]
inventory = /etc/ansible/hosts
remote_user = root  # Replace with your actual SSH username
host_key_checking = False  # Optional, disable SSH key checking
EOF

Create ansible inventory /etc/ansible/hosts file
cat <<EOF > /etc/ansible/hosts
# This is the default ansible 'hosts' file.
#
# It should live in /etc/ansible/hosts
#
#   - Comments begin with the '#' character
#   - Blank lines are ignored
#   - Groups of hosts are delimited by [header] elements
#   - You can enter hostnames or ip addresses
#   - A hostname/ip can be a member of multiple groups

# Ex 1: Ungrouped hosts, specify before any group headers:

[web]
192.168.157.149
[dev]
192.168.157.145

[dns]
centos-worker-1
centos-worker-2

[common:children]
web
dns

## green.example.com
## blue.example.com
## 192.168.100.1
## 192.168.100.10

# Ex 2: A collection of hosts belonging to the 'webservers' group:

## [webservers]
## alpha.example.org
## beta.example.org
## 192.168.1.100
## 192.168.1.110

# If you have multiple hosts following a pattern, you can specify
# them like this:

## www[001:006].example.com

# You can also use ranges for multiple hosts:

## db-[99:101]-node.example.com

# Ex 3: A collection of database servers in the 'dbservers' group:

## [dbservers]
##
## db01.intranet.mydomain.net
## db02.intranet.mydomain.net
## 10.25.1.56
## 10.25.1.57


# Ex4: Multiple hosts arranged into groups such as 'Debian' and 'openSUSE':

## [Debian]
## alpha.example.org
## beta.example.org

## [openSUSE]
## green.example.com
## blue.example.com

EOF


Check entry in inventory file /etc/ansible/hosts
ansible <ip-address-worker01> --list-hosts
eg. ansible 192.168.157.149 --list-hosts

# to check all worker machine 
ansible all --list-hosts
# check with hosts name
ansible <hostsname> --list-hosts
eg. ansible ansible-worker01 --list-hosts
# check entry with group
ansible <group-name> --list-hosts
ansible <group-name1> <group-name2> --list-hosts
eg. ansible web-server --list-hosts
# group inside group  entry in ansible inventory /etc/ansible/hosts
[parent-group-name:children] # children is key word.
group01-name
group02-name
# 
ansible <group01>:<group02> --list-hosts


[common:children]
web-server
dns-server

ansible common --list-hosts


Create custom inventory file 
touch  /ansible/my-inventory 
[webserver]
192.168.157.149

[dnsserver]
192.168.157.150

ansible all --list-hosts -i /root/ansible/my-inventory
If we don't want to use default inventory path we need to change in /etc/ansible/ansible.cfg file 

vim /etc/ansible/ansible.cfg
inventory = /etc/ansible/hosts 
inventory = /root/ansible/my-inventory 

ansible all --lists-hosts
ansible dnsserver --list-hosts
ansible webserver --list-hosts


Ansible lab setup for normal user .

Create two user
useradd -m -s /bin/bash <username> && echo "<username>:<password>" | sudo chpasswd
useradd -m -s /bin/bash harry && echo "harry:password" | sudo chapsswd 
useradd -m -s /bin/bash sysops && echo "sysops:password" | sudo chapsswd

Only root user has permission to write in this file
ls -l /etc/ansible/hosts
-rw-r--r--. 1 root root 1285 Mar 22 04:32 /etc/ansible/hosts

So each user will create their own inventory file 
cat <<EOF | tee /home/sysops/sysops-inv
[sysops-server]
192.168.157.149
192.168.157.133
EOF
cat <<EOF | tee /home/harry/harry-inv
[harryserver]
192.168.157.150
192.168.157.136
EOF

ansible all --list-hosts -i sysops-inv
ansible all --list-hosts -i harry-inv

To overcome from the -i option 
we copy /etc/ansible/ansible.cfg file every user.
cp /etc/ansible/ansible.cfg /home/sysops/ansible/
cp /etc/ansible/ansible.cfg /home/harry/ansible/

Set environment variable for configuration file .cfg
 export ANSIBLE_CONFIG=/home/sysops/ansible/ansible.cfg
 export ANSIBLE_CONFIG=/home/harry/ansible/ansible.cfg

cat <<EOF >>  ~/.bashrc

# Exporting ansible .cfg file for sysops user
export ANSIBLE_CONFIG=/home/sysops/ansible/ansible.cfg
EOF

cat <<EOF >> ~/.bashrc

# Exporting ansible .cfg file for harry user
export ANSIBLE_CONFIG=/home/harry/ansible/ansible.cfg
EOF

# To apply the changes in both users, run:
source ~/.bashrc

Now all user can change the their inventory path 
vim /home/sysops/ansible/ansible.cfg
inventory = /home/sysops/ansible/sysops-inv

vim /home/harry/ansible/ansible.cfg
inventory = /home/harry/ansible/harry-inv

Check by 
ansible --version
ansible sysops-server --list-hosts
ansible harry-server --list-hosts
ansible all --list-hosts



HOW TO USE ANSIBLE COMMAND 

Note: 
	if you are running any command in with root user or any normal user , so on worker  nodes  that user should be exists.
	Now on /etc/ansible/ansible.cfg file  this should be uncomment 
host_key_checking = False  # Optional, disable SSH key checking


syntax: 
ansible <group-name/ip-address> -m command -a ""
	group-name/ip-address = worker nodes ip or group-name
	-m = module command-name
	-a  = arguments in quotes
	
Now if run this command  again get some error ..
ansible web -m command -a "uptime"
192.168.157.149 | UNREACHABLE! => {
    "changed": false,
    "msg": "Failed to connect to the host via ssh: Warning: Permanently added '192.168.157.149' (ECDSA) to the list of known hosts.\r\nroot  # Replace with your actual SSH username@192.168.157.149: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).",
    "unreachable": true
}

We need to configure some sshpass
wget https://sourceforge.net/projects/sshpass/files/sshpass/1.05/sshpass-1.05.tar.gz
tar -xvzf sshpass-1.05.tar.gz
sudo yum groupinstall "Development Tools" 
cd sshpass-1.05/
 ./configure
 make
 sudo make install
 sshpass -V

But we need to specify -k  for prompt password and -u for user.
ansible web -m command -a "uptime" -k -u root
SSH password:
192.168.157.149 | CHANGED | rc=0 >>
 19:55:59 up 58 min,  2 users,  load average: 0.04, 0.10, 0.09

Raw module 
 used to run multiple command in one go. 
ansible web -m raw -a "ls;date;uptime" -k -u root
SSH password:
192.168.157.149 | CHANGED | rc=0 >>
anaconda-ks.cfg                     Music            sshpass-1.05 sshpass-1.05.tar.gz
Desktop                             Pictures         Templates
Documents                           Public           Videos	Downloads                           
Sat Mar 22 20:01:13 PDT 2025
 20:01:13 up  1:03,  2 users,  load average: 0.12, 0.08, 0.09
Shared connection to 192.168.157.149 closed.


To overcome from the password prompt -k  
we use ssh private key 
in ansible-master node create ssh key 
ssh-keygen
ls -l .ssh/

ssh-copy-id root@192.168.157.149
password:
Verify on ansible-worker-node01
ls -l ~/.ssh/
total 8
-rw-------. 1 root root 572 Mar 22 20:04 authorized_keys

to overcome form the defined user -u 
set the ansible_user in your inventory file (e.g., /etc/ansible/hosts or a custom inventory file).
[web]
192.168.157.149 ansible_user=root

You can also set the default user globally in the ansible.cfg file, which is typically located in /etc/ansible/ansible.cfg or in your home directory (~/.ansible.cfg):

[defaults]
remote_user = root

Even though you've set remote_user = root in the Ansible configuration, SSH on the remote host must allow root login. On the remote machine (192.168.157.149), check the following:

    Open the SSH configuration file /etc/ssh/sshd_config:

sudo vim /etc/ssh/sshd_config

Ensure the following line is present and not commented out:

PermitRootLogin yes

If it is set to no or commented out, it would prevent SSH access as root.

Restart the SSH service after making any changes:

    sudo systemctl restart sshd

2. Check the SSH Public Key Authentication

Even though you've copied the SSH public key (/root/.ssh/id_rsa.pub) to the remote server using ssh-copy-id, there may still be issues with how the keys are being used. Let’s verify a few things:

    Permissions on the .ssh directory and authorized_keys file on the target machine (192.168.157.149):

sudo chmod 700 /root/.ssh
sudo chmod 600 /root/.ssh/authorized_keys

Test the SSH connection manually to confirm that the key is being used correctly. Try to SSH as root into the target machine:

ssh root@192.168.157.149

# verify
 ansible web -m command -a "ls -la"
ansible web -m raw -a "ls -l;date;uptime"

####################################################
To  check all modules
ansible-doc -l 

Adhoc Command

Copy module
# To get help of copy module.
ansible-doc copy

# Copy /etc/passwd file to /tmp dir
ansible web -m copy -a 'src=/etc/passwd dest=/tmp'
# Check that /etc/passwd file is copied  in /tmp directory 
ansible web -m command -a 'ls -l /tmp/passwd'

# Task to create two user "aws" & "azure" on ansible-worker-nodes, copy /etc/group file with owner=aws group=azure mode='0777' in /tmp directory .
useradd -m -s /bin/bash aws && echo "aws:password" | sudo chpasswd 
useradd -m -s /bin/bash azure && echo "azure:password" | sudo chpasswd
# Verify user 
id aws
id azure
ansible web -m copy -a "src=/etc/group dest=/tmp owner=aws group=azure mode='0777'"
# Verify 
ansible web -m command -a "ls -l /tmp"


# if we copy same file but append some text "Copy a new "/etc/group" file into place, backing
up the original if it differs from the copied version.
Adding user Linux to make some changes in /etc/group file 
useradd -m -s /bin/bash linux && echo "linux:password" | sudo chpasswd

ansible web -m copy -a "src=/etc/group dest=/tmp owner=aws group=azure mode='0777' backup=yes"

ansible web -m command -a "ls -lh /tmp/group"

# copy from target machine to target machine. 
ansible web -m copy -a "src=/var/log/dnf.log remote_src=yes dest=/tmp owner=aws group=azure mode=0770"
#Verify
ansible web -m command -a "ls -lh /tmp/dnf.log"

################################################
Ansible Fetch module

It is used for fetching files from remote machines and storing them in a file tree, organized by hostname. Files that already exist at 'dest' will be overwritten if they are different than the 'src'. This module is also supported for windows targets. 

# to check doc of fetch module
ansible-doc fetch 
ansible web -m fetch -a "src=/var/log/dnf.log dest=/logs"
# Verify
tree /logs/
/logs/
└── 192.168.157.149
    └── var
        └── log
            └── dnf.log

3 directories, 1 file


################################################

Ansible File Module

To check file module doc
ansible-doc file

Create directory in /tmp dir using file module
ansible web -m file -a "/tmp/file-module-dir state=directory"
ansible web -m command -a "ls -lh /tmp"

Create file in /tmp file using file module
ansible web -m file -a "/tmp/file-module-file state=touch owner=aws group=azure mode=0770"
ansible web -m command -a "ls -lh /tmp"

To delete dir with file module
ansible web -m file -a "path=/tmp/file-module-dir state=absent"
ansible web -m command -a "ls -lh /tmp"

Create a soft link of the file /tmp/test-dir/test-file  to /tmp/symbolic-link-file
ansible web -m file -a "src=/tmp/test-dir/test-file dest=/tmp/symbolic-link-file state=link"
ansible web -m command -a "ls -lh /tmp"

Create a hard link of the file /tmp/test-dir/test-file  to /tmp/symbolic-hard-link-file
ansible web -m file -a "src=/tmp/test-dir/test-file dest=/tmp/symbolic-hard-link-file state=hard"
ansible web -m command -a "ls -lh /tmp"


#######################################

Shell module
The `shell' module takes the command name followed by a list of space-delimited arguments . Either a free form command  or 	`cmd' parameter is required .
It is almost exactly like the ansible comamnd module but runs the command throught a shell /bin/sh or the remote node. 

To read doc for shell module
ansible-doc shell

To do this example create script test-script.sh
#!/bin/bash
echo  "***** Test script to create dir && files *****"
mkdir /tmp/test-dir
cd /tmp/test-dir
touch abc
cp -rvf /etc/* /tmp/test-dir
echo "******Script run successfully!!******"

Assign executeable persmission 
chomod +x test-script.sh

copy to ansible-worker nodes
 ansible web -m copy -a "src=/root/ansible/script/test-script.sh dest=/tmp mode=0755"

Verify
ansible web -m command -a "ls -lh /tmp"

Run script 
ansible web -m shell -a 'sh /tmp/test-script.sh'

Verify
ansible web -m command -a "ls -lh /tmp/test-dir/"

#############################################
Ansible Package Module
This modules manages package on a target without specifying a package manager module  like yum, apt, ... . It is convenient to use in an package manger. package call behind the module of the package manager used by the operation system discovered by the module ansible.builtin.setup . If setup was not yet run, package will run it. This module acts as a proxy to the underlying package manger module. while all arguments  will be passed to the underling module, not all modules support the small arguments.


To read doc for package module
ansible-doc package


Install httpd package on ansible worker nodes
ansible web -m package -a 'name=httpd' state=present'
Verify
ansible web -m raw -a "rpm -qa | grep httpd"

To remove package 
ansible web -m package -a name=httpd state=absent"

NOte: this key word can be used to install or remove the packages :
		absent, present, installed , removed , latest

use attributes for package module
The required package manger module to use yum, apt, and so no . The default auto will use existing facts or try to autodetect it. 
You should only use this field if the automatic selection is not working  for some reason. 
default: auto

ansible web -m package -a "name=samba* state=latest use=yum"

###############################################

Ansible yum module
there are 2 module yum and yum_repository

Check with ansible doc command 
ansible-doc -l | grep yum

yum_repository
Add or remove yum repository is RPM-based Linux distributions. IF you wish to update an repository definition use [community.general.ini_file] instead.

Check doc for  ansible yum_repository
ansible-doc yum_repository

Configure yum_repository
ansible web -m yum_repository -a "name=yum-server description='this is my first yum server' file=my_yum_server baseurl=https://download.fedoraproject.org/pub/epel/$releasever/$basearch/ gpgcheck=no enabled=yes"

Verify
ansible web -m command -a "yum repolist"
ansible web -m raw -a  "ls -lh /etc/yum.repos.d/ | grep my_yum_server"
ansible web -m  command -a " cat /etc/yum.repos.d/my_yum_server.repo"
[yum-server]
baseurl = https://download.fedoraproject.org./pub/epel///
enabled = 1
gpgcheck = 0
name = this is my first yum sever

To remove specific repo yum_repository
ansible web -m yum_repository -a "name=yum-server state=absent file=my_yum_server"
ansible web -m command -a "ls -lh /etc/yum.repos.d/"


###########################################
yum module

To check doc
ansible-doc yum

To install package
ansible web -m yum -a "name=httpd state=latest"
ansible web -m raw -a "rpm -qa | grep httpd"

To remove package
ansible web -m yum -a "name=httpd state=absent"
ansible web -m raw -a "rpm -qa | grep httpd"

To install package from particular repository
Check the available  repo
ansible web -m raw -a "yum repolist"
ansible web -m yum -a "name=httpd state=present enablerepo=baseos"
ansible web -m raw -a "rpm -qa | grep httpd"

To update all package in the system
ansible web  -m yum -a "name='*' state=latest"

Upgrade all packages, excluding kernel & foo related packages

#############################################################
service module
Controls services on remote hosts. Supported init systems include BSD init, OpenRC, SysV, Solaris SMF, system, upstart,. This module acts as a proxy to the underlying service manger module. While all arguments will be passwd to the underlying module, not all module support the same argument. 

To check doc for service module
ansible-doc service

For this service firstly we install httpd server then append text inside /var/www/html/index.html file 
ansible web -m yum -a "name=httpd state=latest"

ansible web -m copy -a "content='this is demo content from httpd server' dest=/var/www/html/index.html"

Check the content of the file /var/www/html/index.html
ansible web -a command -a "cat /var/www/html/index.html"

Check the status of the service
ansible web -m systemd -a "name=httpd state=status"

permanently Start httpd.service
ansible web -m service -a "name=httpd state=started enabled=yes"

ansible web -m command -a "systemctl status httpd"


permanently stop htted.service
ansible web -m service -a "name=httpd state=stopped enabled=no"
Reload service
ansible web -m service -a "name=httpd state=reloaded"
Restart service
ansible web -m service -a "name=httpd state=restarted"

####################################################
Ansible User & Group Module 

Group
Manage presence of groups on a host. For Windows targets, use the [ansible.windows.win_group]  module instead. 

To check doc for group
ansible-doc group

To create group
ansible web -m group -a "name=wipro state=present"
ansible web -m command -a "tail -2 /etc/group"

To delete group
ansible web -m group -a "name=wipro state=absent"
ansible web -m command -a "tail -2 /etc/group"

User
Manage user account and user attributes. For windows targets , use the  [ansible.windows.win_user] module instead. 

To check doc for user
ansible-doc user

Create user  named johnd and assign uid=1050 group=azure comment= john sysadmin 
ansible web -m user -a "name=johnd comment='John sysadmin' uid=1050 group=azure"
Verify
ansible web -m command -a "id johnd"
ansible web -m command -a "tail -2 /etc/passwd"
ansible web -m command -a "getent group 1002"  # it show gid of azure group

Change the existing user shell=/sbin/nologin and add group=aws,azure 
ansible web -m user -a "name=johnd shell=/sbin/nologin  groups=azure,aws append=yes"
ansible web -m command -a "id johnd"
ansible web -m command -a "tail -2 /etc/passwd"

To delete user johnd also home dir
ansible web -m user -a "name=johnd state=absent remove=yes"
ansible web -m command -a "id johnd"
ansible web -m command -a "ls -l /home"

Create ssh key for user
ansible web -m user -a "name=aws generate_ssh_key=yes ssh_key_bits=2048 ssh_key_file=.ssh/id_rsa"

Verify
ansible web -m command -a "ls -la /home/aws/.ssh"

####################################################

Ansible lineinfile module

 This module ensures a particular line is in a file, or replace
        an existing line using a back-referenced regular expression.
        This is primarily useful when you want to change a single line
        in a file only. See the [ansible.builtin.replace] module if
        you want to change multiple, similar lines or check
        [ansible.builtin.blockinfile] if you want to
        insert/update/remove a block of lines in a file. For other
        cases, see the [ansible.builtin.copy] or
        [ansible.builtin.template] modules.

to check doc of lineinfile
ansible-doc linefile

to append line in file /etc/sudoers
ansible web -m lineinfile -a "path=/etc/sudoers line='sysops   ALL=(ALL)   ALL'"
ansible web -m command  -a "tail -2 /etc/sudoers"

To delete any text 
ansible web -m lineinfile -a "path =/etc/sudoers line='sysops   ALL=(ALL)   ALL'  state=absent"
ansible web -m command  -a "tail -2 /etc/sudoers"


Insert beginning of the file (BOF)
ansible web -m lineinfile -a "path=/etc/sudoers line='sysops   ALL=(ALL)   ALL' insertafter=BOF"
ansible web -m command  -a "head -2 /etc/sudoers"

Delete line BOF 
 ansible web -m lineinfile -a "path=/etc/sudoers line='sysops  ALL=(ALL)  ALL' insertafter=BOF state=absent"
ansible web -m command  -a "head -2 /etc/sudoers"

Insert EOF (End Of File)
 ansible web -m lineinfile -a "path=/etc/sudoers line='sysops  ALL=(ALL)  ALL' insertafter=EOF "
ansible web -m command  -a "tail -2 /etc/sudoers"

Delete line EOF 
 ansible web -m lineinfile -a "path=/etc/sudoers line='sysops  ALL=(ALL)  ALL' insertafter=EOF state=absent"
ansible web -m command  -a "tail -2 /etc/sudoers"

Insert after specific line 
ansible web -m lineinfile -a "path=/etc/sudoers line='sysops  ALL=(ALL)   ALL' insertafter='^root'"
ansible web -m command -a "grep -A 2 'root' /etc/sudoers"

Delete specific line
ansible web -m lineinfile -a "path=/etc/sudoers line='sysops  ALL=(ALL)   ALL' insertafter='^root' state=absent"
ansible web -m command -a "grep -A 2 'root' /etc/sudoers"

Insert before specific line
ansible web -m lineinfile -a "path=/etc/sudoers line='sysops  ALL=(ALL)   ALL' insertbefore='^root'"
ansible web -m command -a "grep -A 2 'root' /etc/sudoers"

Delete specific line
ansible web -m lineinfile -a "path=/etc/sudoers line='sysops  ALL=(ALL)   ALL' insertbefore='^root' state=absent"
ansible web -m command -a "grep -A 2 'root' /etc/sudoers"

To replace particular expression with line
ansible web -m lineinfile -a "path=/etc/sudoers  line='syosps  ALL=(ALL)   ALL'  regexp='temp-user' "
ansible web -m command -a "grep 'sysops' /etc/sudoers"

to delete specific line
ansible web -m lineinfile -a "path=/etc/sudoers line='sysops  ALL=(ALL)   ALL'  state=absent"

to delete with regexp
ansible web -m lineinfile -a "path=/etc/sudoers regexp='^temp-user' state=absent "

TASK:
To disable selinux 
ansible web -m lineinfile -a "path=/etc/selinux/config  regexp='^SELINUX=' line='SELINUX=disabled'"


##########################################################

Ansible Playbook

Ad-hoc method
file method (playbook)

It support 2 lang. 
yaml/yml
json

3 ways to write playbook
1. Single line format
2. Multi line format
3. Dictionary format (easy)

Dictionary format
vim dictonary-fmt.yaml
- hosts: web                   #(group-name) target machine
  tasks:                          # task
    - copy:                       # module
         src: /etc/passwd    # attributes
         dest: /tmp/
         owner: aws
         group: azure
         mode: 0770

ansible-playbook dictonary-fmt.yaml

PLAY [web] *****************************************************************************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.157.149]

TASK [copy] ****************************************************************************
changed: [192.168.157.149]

PLAY RECAP *****************************************************************************
192.168.157.149            : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


create multiple task
vim dictonary-fmt.yaml
- hosts: web               # (group-name) target machine
  tasks:                   # task
  # copying file with change onwer group & file permission
    - copy:                # module
        src: /etc/passwd   # attributes
        dest: /tmp/
        owner: aws
        group: azure
        mode: 0770

   # Creating directory
    - file:
        path: /tmp/ansible
        state: directory

  # Create file
    - file:
        path: /tmp/ansible/test.txt
        state: touch

ansible-playbook dictonary-fmt.yaml

PLAY [web] *****************************************************************************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.157.149]

TASK [copy] ****************************************************************************
changed: [192.168.157.149]

TASK [file] ****************************************************************************
changed: [192.168.157.149]

TASK [file] ****************************************************************************
changed: [192.168.157.149]

PLAY RECAP *****************************************************************************
192.168.157.149            : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

TASK for Dictionary format
Install httpd package configure content inside and start & enable service 

vim dict-task-1.yaml
- hosts: web
  tasks:
    # Install httpd package
    - yum:
        name: httpd
        state: latest

    # appending content
    - copy:
        content: 'Configure the HTTPD server using the Ansible playbook dict-fmt.'
        dest: /var/www/html/index.html

    # service start & enable
    - service:
        name: httpd
        state: started
        enabled: yes

ansible-playbook dict-task-1.yaml

PLAY [web] *****************************************************************************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.157.149]

TASK [yum] *****************************************************************************
changed: [192.168.157.149]

TASK [copy] ****************************************************************************
changed: [192.168.157.149]

TASK [service] *************************************************************************
changed: [192.168.157.149]

PLAY RECAP *****************************************************************************
192.168.157.149            : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

curl http://192.168.157.149:80
Configure the HTTPD server using the Ansible playbook dict-fmt.


#########################################################

Singleline format
vim singleline-fmt.yaml
- hosts: web
  tasks:
    - copy: src=/etc/group dest=/tmp owner=aws group=azure mode=0770
    - file: path=/tmp/aws state=directory
    - yum: name=tree state=latest
    - service: name=httpd state=restarted

ansible-playbook singleline-fmt.yaml

PLAY [web] *****************************************************************************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.157.149]

TASK [copy] ****************************************************************************
changed: [192.168.157.149]

TASK [file] ****************************************************************************
changed: [192.168.157.149]

TASK [yum] *****************************************************************************
changed: [192.168.157.149]

TASK [service] *************************************************************************
changed: [192.168.157.149]

PLAY RECAP *****************************************************************************
192.168.157.149            : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


########################################################
Multiline format

 multiline-fmt.yaml
- hosts: web
  tasks:
    - copy: src=/etc/shadow
            dest=/tmp
            owner=aws
            group=azure
            mode=0770

    - file: path=/tmp/azure
            state=directory

    - yum:  name=nfs-utils
            state=latest

    - service: name=nfs-server
               state=started
               enabled=yes

ansible-playbook multiline-fmt.yaml

PLAY [web] *****************************************************************************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.157.149]

TASK [copy] ****************************************************************************
changed: [192.168.157.149]

TASK [file] ****************************************************************************
changed: [192.168.157.149]

TASK [yum] *****************************************************************************
ok: [192.168.157.149]

TASK [service] *************************************************************************
changed: [192.168.157.149]

PLAY RECAP *****************************************************************************
192.168.157.149            : ok=5    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


 ansible web -m command -a "service nfs-server status"
 ansible web -m command -a "ls -l /tmp"

###########################################################
Json format

User online converter yaml to json
https://onlineyamltools.com/convert-yaml-to-json


vim json-dict-fmt.json
[
  {
    "hosts": "web",
    "tasks": [
      {
        "copy": {
          "src": "/etc/hosts",
          "dest": "/tmp/",
          "owner": "aws",
          "group": "azure",
          "mode": 0770
        }
      },
      {
        "file": {
          "path": "/tmp/json-dict-fmt",
          "state": "directory"
        }
      },
      {
        "file": {
          "path": "/tmp/json-dict-fmt/json-dict.txt",
          "state": "touch"
        }
      }
    ]
  }
]

 ansible-playbook json-dict-fmt.json

PLAY [web] *****************************************************************************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.157.149]

TASK [copy] ****************************************************************************
changed: [192.168.157.149]

TASK [file] ****************************************************************************
changed: [192.168.157.149]

TASK [file] ****************************************************************************
changed: [192.168.157.149]

PLAY RECAP *****************************************************************************
192.168.157.149            : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

vim  json-single-fmt.json
[
  {
    "hosts": "web",
    "tasks": [
      {
        "copy": "src=/etc/group dest=/tmp owner=aws group=azure mode=0770"
      },
      {
        "file": "path=/tmp/single-json-fmt state=directory"
      },
      {
        "yum": "name=tree state=latest"
      },
      {
        "service": "name=httpd state=restarted"
      }
    ]
  }
]

 ansible-playbook json-single-fmt.json

PLAY [web] *****************************************************************************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.157.149]

TASK [copy] ****************************************************************************
changed: [192.168.157.149]

TASK [file] ****************************************************************************
changed: [192.168.157.149]

TASK [yum] *****************************************************************************
ok: [192.168.157.149]

TASK [service] *************************************************************************
changed: [192.168.157.149]

PLAY RECAP *****************************************************************************
192.168.157.149            : ok=5    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


vim multi-json-fmt.json
[
  {
    "hosts": "web",
    "tasks": [
      {
        "copy": "src=/etc/shadow dest=/tmp owner=aws group=azure mode=0770"
      },
      {
        "file": "path=/tmp/azure state=directory"
      },
      {
        "yum": "name=nfs-utils state=latest"
      },
      {
        "service": "name=nfs-server state=started enabled=yes"
      }
    ]
  }
]

 ansible-playbook multi-json-fmt.json

PLAY [web] *****************************************************************************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.157.149]

TASK [copy] ****************************************************************************
changed: [192.168.157.149]

TASK [file] ****************************************************************************
changed: [192.168.157.149]

TASK [yum] *****************************************************************************
ok: [192.168.157.149]

TASK [service] *************************************************************************
ok: [192.168.157.149]

PLAY RECAP *****************************************************************************
192.168.157.149            : ok=5    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


#######################################################
lec-20
Define multi-host/target node in single ansible-playbook

 vim multi-host.yaml
- name: Create file on Web and copy it to Dev
  hosts: web
  tasks:
    - name: Create file on 192.168.157.149 (Web)
      file:
        path: /tmp/host-01.txt
        state: touch

- name: dev hosts
  hosts: dev
  tasks:
   - user:
      name: katherine
      comment: "actress group"
      shell: /bin/bash
 ansible-playbook multi-host.yaml

PLAY [Create file on Web and copy it to Dev] ********************************************************

TASK [Gathering Facts] ******************************************************************************
ok: [192.168.157.149]

TASK [Create file on 192.168.157.149 (Web)] *********************************************************
changed: [192.168.157.149]

PLAY [dev hosts] ************************************************************************************

TASK [Gathering Facts] ******************************************************************************
ok: [192.168.157.148]

TASK [user] *****************************************************************************************
changed: [192.168.157.148]

PLAY RECAP ******************************************************************************************
192.168.157.148            : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
192.168.157.149            : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

Check 
ansible dev -m command -a "id katherine"
192.168.157.148 | CHANGED | rc=0 >>
uid=1002(katherine) gid=1002(katherine) groups=1002(katherine)
ansible web -m command -a "ls -l /tmp/host-01.txt"
192.168.157.149 | CHANGED | rc=0 >>
-rw-r--r--. 1 root root 0 Apr  1 09:18 /tmp/host-01.txt


#########################################################
lec 21

Reference call from another file using  import_tasks attribute

 vim main.yaml
- name: this is web server group machine
  hosts: web
  tasks:
    - import_tasks: task1.yaml

- name: the is dev server group machine
  hosts: dev
  tasks:
    - import_tasks: task2.yaml

vim task1.yaml
- name: copy /etc/passwd to /tmp directory
  copy:
    src: /etc/passwd
    dest: /tmp
    owner: aws
    group: azure
    mode: 0770

- name: create directory /tmp/ansible
  file:
    path: /tmp/ansible
    state: directory

vim task2.yaml
 - name: installing httpd package
  yum:
    name: httpd
    state: latest

- name: start & enable httpd service
  service:
    name: httpd
    state: started
    enabled: yes


import multiple file in same tasks
vim main.yaml
- name: this is web server group machine
  hosts: web
  tasks:
    - import_tasks: task1.yaml
    - import_tasks: task3.yaml

Task:
allow port 8082 in firewalld 

vim firewall.yaml
- name: task run on dev servers
  hosts: dev
  tasks:
    - name: allow port 8082 in firewalld
      firewalld:
        port: 8082/tcp
        zone: public
        permanent: true
        state: enabled
        immediate: true


############################################################
lec 22
configure apache server 

vim web-server.conf
- name: Configure web server in web group machine
  hosts: dev
  tasks:
   - name: Installing httpd package
     yum:
       name: httpd
       state: latest

   - name: copy sourcecode to /var/www/html/
     copy:
       src: /root/ansible/playbook/apache-sever-conf/sourcecode/
       dest: /var/www/html/

   - name: chage the port no. 80 to 8080
     lineinfile:
       path: /etc/httpd/conf/httpd.conf
       regexp: '^Listen'
       insertafter: '^#Listen'
       line: 'Listen 8080'

   - name: allow port 8080 in firewalld
     firewalld:
       port: 8080/tcp
       zone: public
       permanent: true
       state: enabled
       immediate: true

   - name: start & enable httpd service
     service:
       name: httpd
       state: started
       enabled: yes

 ansible-playbook web-server.yaml

PLAY [Configure web server in web group machine] **************************************************************************************************************************

TASK [Gathering Facts] ****************************************************************************************************************************************************
ok: [192.168.157.151]

TASK [Installing httpd package] *******************************************************************************************************************************************
changed: [192.168.157.151]

TASK [copy sourcecode to /var/www/html/] **********************************************************************************************************************************
changed: [192.168.157.151]

TASK [chage the port no. 80 to 8080] **************************************************************************************************************************************
changed: [192.168.157.151]

TASK [allow port 8080 in firewalld] ***************************************************************************************************************************************
changed: [192.168.157.151]

TASK [start & enable httpd service] ***************************************************************************************************************************************
changed: [192.168.157.151]

PLAY RECAP ****************************************************************************************************************************************************************
192.168.157.151            : ok=6    changed=5    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

Check :
systemctl status httpd.service
firewall-cmd --list-all
sed -n '/Listen 8080/p' /etc/httpd/conf/httpd.conf
hostname -i 
 curl http://192.168.157.151:8080
Or 
browse from browser  http://192.168.157.151:8080

###########################################################
lec 25 Ansible Variable Part-1


vim variable.yaml
- name: Varaible demonstaration
  hosts: dev
  vars:
    mydir: /tmp/var-dir
    myfile: /etc/passwd
    mypkg:
      - httpd
      - nfs-utils
      - tree

  tasks:
    - name: create dirctory "{{ mydir }}"
      file:
        path: "{{ mydir }}"
        state: directory

    - name: copy file "{{ myfile }}" to "{{ mydir }}"
      copy:
        src: "{{ myfile }}"
        dest: "{{ mydir }}"
        owner: elliot
        group: harry
        mode: 0770

    - name: Installing package "{{ mypkg }}"
      yum:
        name: "{{ mypkg }}"
        state: latest
[root@centos-master variables]# ansible-playbook variable.yaml

PLAY [Varaible demonstaration] **********************************************************************

TASK [Gathering Facts] ******************************************************************************
ok: [192.168.157.151]

TASK [create dirctory "/tmp/var-dir"] ***************************************************************
changed: [192.168.157.151]

TASK [copy file "/etc/passwd" to "/tmp/var-dir"] ****************************************************
changed: [192.168.157.151]

TASK [Installing package "['httpd', 'nfs-utils', 'tree']"] ******************************************
changed: [192.168.157.151]

PLAY RECAP ******************************************************************************************
192.168.157.151            : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

Check 
rpm -q httpd
tree /tmp
ls -l /tmp/var-dir/

##########################################################
lec 24 
Ansible Variable part-2 

Variable define in another file .
myvariable/var.yaml
mydir: /tmp/var-directory
myfile: /etc/fstab
mypkg:
  - httpd
  - tree

[root@centos-master variables]# cat main.yaml
- name: Varaible demonstaration
  hosts: dev
  vars_files:
    - /root/ansible/playbook/variables/myvariable/var.yaml

  tasks:
    - name: create dirctory "{{ mydir }}"
      file:
        path: "{{ mydir }}"
        state: directory

    - name: copy file "{{ myfile }}" to "{{ mydir }}"
      copy:
        src: "{{ myfile }}"
        dest: "{{ mydir }}"
        owner: elliot
        group: harry
        mode: 0770

    - name: Installing package "{{ mypkg }}"
      yum:
        name: "{{ mypkg }}"
        state: latest

[root@centos-master variables]# ansible-playbook main.yaml

PLAY [Varaible demonstaration] **********************************************************************

TASK [Gathering Facts] ******************************************************************************
ok: [192.168.157.151]

TASK [create dirctory "/tmp/var-directory"] *********************************************************
changed: [192.168.157.151]

TASK [copy file "/etc/fstab" to "/tmp/var-directory"] ***********************************************
changed: [192.168.157.151]

TASK [Installing package "['httpd', 'tree']"] *******************************************************
changed: [192.168.157.151]

PLAY RECAP ******************************************************************************************
192.168.157.151            : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

Check 
rpm -q httpd
tree /tmp

#############################################

Lecture 23
Ansible Variable part-3


vars_files:
    - /root/ansible/playbook/variables/myvariable/var.yaml


Define variable in command -line 
 use option -e variable=value -e variable=value1,value2
syntax:
	ansible-playbook playbook-name.yaml -e variable1=value -e varaible2=value1,value2

eg.
vim  main.yaml
- name: Varaible demonstaration
  hosts: dev

  tasks:
    - name: create dirctory "{{ mydir }}"
      file:
        path: "{{ mydir }}"
        state: directory

    - name: copy file "{{ myfile }}" to "{{ mydir }}"
      copy:
        src: "{{ myfile }}"
        dest: "{{ mydir }}"
        owner: elliot
        group: harry
        mode: 0770

    - name: Installing package "{{ mypkg }}"
      yum:
        name: "{{ mypkg }}"
        state: latest
[root@centos-master variables]# ansible-playbook main.yaml -e mydir=/tmp/cmd-dir -e myfile=/etc/passwd -e mypkg=httpd,tree

PLAY [Varaible demonstaration] **********************************************************************

TASK [Gathering Facts] ******************************************************************************
ok: [192.168.157.151]

TASK [create dirctory "/tmp/cmd-dir"] ***************************************************************
changed: [192.168.157.151]

TASK [copy file "/etc/passwd" to "/tmp/cmd-dir"] ****************************************************
changed: [192.168.157.151]

TASK [Installing package "httpd,tree"] **************************************************************
changed: [192.168.157.151]

PLAY RECAP ******************************************************************************************
192.168.157.151            : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


Ansible Playbook Variables Interview Question:

Preference of Calling Variables

Suppose we have defined variables in a playbook like this:

vars:
  mydir: /tmp/playbook-var-dir
  myfile: /etc/groups
  mypkg:
    - samba
    - nfs-utils

Now, the same variables are defined on the command line like this:

ansible-playbook playbook-name.yaml \
  -e mydir=/tmp/cmd-line-dir \
  -e myfile=/etc/hosts \
  -e mypkg=tree,httpd

Additionally, the same variables are defined in another file, as shown below, and included in the playbook using vars_files:

# variables/var.yaml
mydir: /tmp/another-file-var-dir
myfile: /etc/shadow
mypkg:
  - samba
  - nfs-utils

And in the playbook:

vars_files:
  - /variables/var.yaml

Question:
Which variables will be used? In other words, which variables have the highest priority?

Ans: 
In Ansible, the variable precedence follows this order (from highest to lowest):

    Command-line variables (-e) — highest priority.

    Variables in vars_files — next priority.

    Variables defined in the playbook (vars) — lowest priority.

So, in this case:

    mydir, myfile, and mypkg from the command line will override the playbook and vars_files values.

    If not set in the command line, the values from vars_files will be used.

    If neither is provided, the playbook variables will be used.
############################################################
lec 26
Ansible Variable
Define variable inventory file 
	NOTE: inventory default path /etc/ansible/hosts

vim /etc/ansible/hosts/
[web]
192.168.157.149  ansible_user=root  mydir=/tmp/inventory-web-dir myfile=/etc/hosts mypkg=tree,nfs-utils
[dev]
192.168.157.151 ansible_user=root mydir=/tmp/inventory-dev-dir myfile=/etc/shadow mypkg=httpd,samba

vim main.yaml
- name: tasks run in all  group
  hosts: all
  tasks: 
     - name: "create directory name {{ mydir }} "
       file:
         path: "{{ mydir }}"
         state: directory
    
     - name: "copy file from {{ myfile }} to {{ mydir }} "
       copy:
          src: "{{ myfile }}"
          dest:  "{{ mydir }}"
          owner: aws
          group: azure
          mode: 0770

     - name: " install some packages {{ mypkg }}"
       yum: 
          name: "{{ mypkg }}"
          state: latest

ansible-playbook main.yaml 

############################################################
lecture 27 
ansible Define variable on the basis of group name in inventory file 
vim /etc/ansible/hosts
[web]
192.168.157.149

[dev]
192.168.157.151

[web:vars]
mydir=/tmp/group-var-inv-dir-web
myfile=/etc/passwd
mykg=httpd,nfs-utils,tree

[dev:vars]
mydir=/tmp/group-var-inv-dir-dev
myfile=/etc/shadow
mykg=httpd,samba,tree

vim playbook.yaml
- name: Running task on all group
  hosts: all                     # all means web, dev group 
  tasks: 
     - name: " create directory  {{ mydir }} "
       file: 
         path: "{{ mydir }}"
         state: directory 

     - name: copy file from {{ myfile }} to {{ mydir }}"
       copy:
          src: "{{ myfile }}"
          dest:  "{{ mydir }}"
          owner: aws
          group: azure
          mode: 0770

     - name: " install some packages {{ mypkg }}"
       yum: 
          name: "{{ mypkg }}"
          state: latest

ansible-playbook playbook.yaml

******* Interview question *********
Define variable in inventory file 
/etc/ansible/hosts

i have define variable in host base Infront of Ip's and group based which has higher priority 

[web]
192.168.157.149 

[dev]
192.168.157.151

[web:vars]
mydir=/tmp/group-var-inv-dir-web
myfile=/etc/passwd
mykg=httpd,nfs-utils,tree

[dev:vars]
mydir=/tmp/group-var-inv-dir-dev
myfile=/etc/shadow
mykg=httpd,samba,tree


Ans:
It will give host variable priority  first then group based. 

###################################################
lec 28 
Ansible Variable 
without ssh -key with user password run ansible playbook 
Allow in /etc/ansible/ansible.cfg  file 

PARAMTER ALLOW OR UNCOMMENT 
	ask_pass = True
	remote_user  = root


anible-playbook playbook-name.yaml 

Define user name password as a variable in inventory file host.

vim /etc/ansible/hosts
[web]
192.168.157.149 ansible_ssh_user=<<username>> ansible_ssh_pass=<<password>> ansible_ssh_port=22

[dev]
192.168.157.151 ansible_ssh_user=<<username>> ansible_ssh_pass=<<password>> ansible_ssh_port=22


Define user name password as a variable in inventory file as group .
[web:vars]
ansible_ssh_user=<<username>> 
ansible_ssh_pass=<<password>>
ansible_ssh_port=22

[dev:vars]
ansible_ssh_user=<<username>>
ansible_ssh_pass=<<password>>
ansible_ssh_port=22

Interview question 
If we have define username and password as variable in inventory file as host variable  and group variable, so which has higher priority . 

Ans: it give host priority first  and then group . 

###################################################
lec -29
Ansible Simple loop 

ansible all --list-hosts
ansible all -m ping

vim without-loop 

- name: ansible playbook without loop , manual file
  tasks:
    - copy:
         src: /etc/passwd
	 dest: /tmp
    - copy:
	 src: /etc/group
	 dest: /tmp
    - copy:
	 src: /etc/shadow
	 dest: /tmp
   - copy:
	 src: /etc/gshadow
	 dest: /tmp

ansible-playbook all without-loop.yaml

ansible playbook with loop 

vim with_loop.yaml
- name: ansible playbook without loop 
  tasks:
    - copy:
         src: "{{ item }}"
	 dest: /tmp
      with_items:
	 - /etc/passwd
	 - /etc/group	
         - /etc/shadow
	 - /etc/gshadow

ansible-playbook  with_loop.yaml


##########################################################

lec 30 
Ansible simple loop

	eg. 2
vim loop-02.yaml

- hosts: all
  tasks:
    - copy:
         src: "{{ item }}"
         dest: /tmp
      with_items:
         - /etc/passwd
	 - /etc/group	
         - /etc/shadow
	 - /etc/gshadow

   - file:
        path: "{{ item }}"
        state: directory 
     with_items:
          - /tmp/directory-1
          - /tmp/directory-2
          - /tmp/directory-3

   - copy:
        src: /etc/passwd
        dest: "{{ item }}"
     with_items:
         - /tmp/directory-1
         - /tmp/directory-2
         - /tmp/directory-3


ansible-playbook  loop-02.yaml

###########################################################
lec 31
Ansible simple loop with variables
eg. 3 

- hosts: all 
  vars:
     mydir:
        - /tmp/directory-1
        - /tmp/directory-2
        - /tmp/directory-3
    
    myfile:
        - /etc/passwd
        - /etc/group
        - /etc/shadow
        - /etc/gshadow

  tasks:
      - copy:
         src: "{{ item }}"
         dest: /tmp
      with_items:
         -  "{{  myfile }}"

   - file:
        path: "{{ item }}"
        state: directory 
     with_items:
          -  "{{ mydir  }}"

   - copy:
        src: /etc/passwd
        dest: "{{ item }}"
     with_items:  "{{ mydir }}"  # we can also call var like this

###########################################################
lec 32 
Ansible simple loop 
eg. 4 

- hosts: all
  tasks:
     -  yum: 
           name: " {{ item }}"    
           state: installed
        with_items:
           - ftp
           - httpd
           - vsftpd
           - nfs-utils

NOTE: Yum module doesn't require loop 
without loop yum module eg. 

- hosts: all
  tasks:
     -  yum: 
           name: 
              - ftp
              - httpd
              - vsftpd
              - nfs-utils
           state: installed

###########################################################
lec 33
Ansible Nested loop 

 vim nested-loop.yaml
- name: "Nested loop eg.- 01"
  hosts: dev
  tasks:
    - name: "copy files from {{ item[0] }} to {{ item[1] }}"
      copy:
        src: "{{ item[0] }}"
        dest: "{{ item[1] }}"
      with_nested:
        - [ '/etc/passwd', '/etc/group', '/etc/shadow' ]
        - [ '/tmp', '/tmp/test1', '/tmp/test2' ]

[root@centos-master loop]# ansible-playbook nested-loop.yaml

PLAY [Nested loop eg.- 01] *********************************************************************************************

TASK [Gathering Facts] *************************************************************************************************
ok: [192.168.157.151]

TASK [copy files from {{ item[0] }} to {{ item[1] }}] ******************************************************************
changed: [192.168.157.151] => (item=['/etc/passwd', '/tmp'])
changed: [192.168.157.151] => (item=['/etc/passwd', '/tmp/test1'])
changed: [192.168.157.151] => (item=['/etc/passwd', '/tmp/test2'])
changed: [192.168.157.151] => (item=['/etc/group', '/tmp'])
changed: [192.168.157.151] => (item=['/etc/group', '/tmp/test1'])
changed: [192.168.157.151] => (item=['/etc/group', '/tmp/test2'])
changed: [192.168.157.151] => (item=['/etc/shadow', '/tmp'])
changed: [192.168.157.151] => (item=['/etc/shadow', '/tmp/test1'])
changed: [192.168.157.151] => (item=['/etc/shadow', '/tmp/test2'])

PLAY RECAP *************************************************************************************************************
192.168.157.151            : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


Same task with variables
 var-nested-loop.yaml
- name: "Nested loop with variables "
  hosts: dev
  vars:
    myfile:
      - /etc/passwd
      - /etc/group
      - /etc/shadow
      - /etc/gshadow
    mydir:
      - /tmp
      - tmp/test1
      - tmp/test2
  tasks:
    - name: copy files
      copy:
        src: "{{ item[0] }}"
        dest: "{{ item[1] }}"
      with_nested:
        - "{{ myfile }}"
        - "{{ mydir }}"
[root@centos-master loop]# ansible-playbook var-nested-loop.yaml

################################################ 

lec 34

Ansible nested loop 
eg. 2 
vim nested-loop-eg.yaml
- hosts: dev
  vars:
     myfile:
        - /etc/passwd
        - /etc/group
        - /etc/shadow
  tasks:
    - copy:
         src: "{{ myfile[0] }}"
         dest: "{{ item[1] }}"
      with_nested:
         - /tmp
         - /tmp/test1
         - /tmp/test2

########################################################

lec 35
Ansible Hash loop 


/etc/passwd  copy to /tmp
/etc/group copy to  /tmp/test01
/etc/shadow copy to  /tmp/test02

# manually way 
vim manuall.yaml 
- hosts: dev
  tasks:
     - copy:
          src: /etc/passwd
          dest: /tmp
    - copy:
          src:  /etc/group
          dest: /tmp/test01
    - copy:
          src: /etc/shadow
          dest: /tmp/test02


# simple loop 
vim simple-loop.yaml 
- hosts: dev
  tasks:
     - copy:
          src: "{{ item }}"
          dest: /tmp
       with_items:
          - /etc/passwd
    - copy:
          src: "{{ item }}"
          dest: /tmp/test01
       with_items:
          - /etc/group
    - copy:
          src: "{{ item }}"
          dest: /tmp/test02
       with_items:
          - /etc/shadow

`
# with hash loop 

vim hash-loop.yaml
- name: hash loop eg.
  hosts: dev
  tasks:
    - name: copy files base on hash loop
      copy:
        src: "{{ item.a }}"
        dest: "{{ item.b }}"
      with_items:
        - { a: '/etc/passwd', b: '/tmp' }
        - { a: '/etc/group',  b: '/tmp/test01' }
        - { a: '/etc/shadow', b: '/tmp/test02' }

[root@centos-master loop]# ansible-playbook hash-loop.yaml

PLAY [hash loop eg.] ****************************************************************************************

TASK [Gathering Facts] **************************************************************************************
ok: [192.168.157.151]

TASK [copy files base on hash loop] *************************************************************************
changed: [192.168.157.151] => (item={'a': '/etc/passwd', 'b': '/tmp'})
changed: [192.168.157.151] => (item={'a': '/etc/group', 'b': '/tmp/test01'})
changed: [192.168.157.151] => (item={'a': '/etc/shadow', 'b': '/tmp/test02'})

PLAY RECAP **************************************************************************************************
192.168.157.151            : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

# Validate it . 
[root@centos-worker-02 tmp]# tree /tmp
/tmp
├── passwd
├── test01
│   └── group
└── test02
    └── shadow

2 directories, 3 files




###########################################################

lec 36 
Ansible hash loop 

Add these user's to this particular group using hash loop 
harry          to  dev-grp
natasha      to test-grp
sarah          to prod-grp 


firstly need to create groups 
then assign groups to users

# without variable 
- name: "Hash loop task-01 Create users with particular group"
  hosts: dev
  vars:
    groups:
      - dev-grp
      - test-grp
      - prod-grp
  tasks:
    - name: "Create group's {{ item }}"
      group:
        name: "{{ item }}"
        state: present
      with_items: "{{ groups }}"

    - name: "Create users and assign to groups "
      user:
        name: "{{ item.user }}"
        groups: "{{ item.group }}"
        state: present
      with_items:
       - { user: 'harry',   group: 'dev-grp' }
       - { user: 'natasha', group: 'test-grp' }
       - { user: 'shara',   group: 'prod-grp' }

# with variable 
vim hash-task01.yaml
- name: "Hash loop task-01 Create users with particular group"
  hosts: dev
  vars:
    users_groups:
       - { user: 'harry',   group: 'dev-grp' }
       - { user: 'natasha', group: 'test-grp' }
       - { user: 'shara',   group: 'prod-grp' }
  tasks:
    - name: "Create group's {{ item.group }}"
      group:
        name: "{{ item.group }}"
        state: present
      loop: "{{ users_groups }}"
    - name: "Create users and assign to groups "
      user:
        name: "{{ item.user }}"
        groups: "{{ item.group }}"
        state: present
      loop: "{{ users_groups }}"
      loop_control:
        label: "{{ item.user }}"

[root@centos-master loop]# ansible-playbook hash-task01.yaml

PLAY [Hash loop task-01 Create users with particular group] *************************************************

TASK [Gathering Facts] **************************************************************************************
ok: [192.168.157.151]

TASK [Create group's {{ item.group }}] **********************************************************************
changed: [192.168.157.151] => (item={'user': 'harry', 'group': 'dev-grp'})
changed: [192.168.157.151] => (item={'user': 'natasha', 'group': 'test-grp'})
changed: [192.168.157.151] => (item={'user': 'shara', 'group': 'prod-grp'})

TASK [Create users and assign to groups] ********************************************************************
changed: [192.168.157.151] => (item=harry)
changed: [192.168.157.151] => (item=natasha)
changed: [192.168.157.151] => (item=shara)

PLAY RECAP **************************************************************************************************
192.168.157.151            : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

########################################################################################################

lec 37 
Ansible Facts

What Are Ansible Facts?

Ansible facts are pieces of information that Ansible automatically gathers about your system (like hostname, IP address, OS version, memory, etc.) before running a playbook.

Think of it like this:

    📦 Ansible checks the system it's going to manage and collects details about it. These details are called facts.


Which Module Gathers Facts in Ansible?

Ansible uses the setup module to gather system information (facts).

So when you run a playbook or a command like:

ansible all -m setup

You're explicitly using the setup module, which collects all the facts from the target machines.
🔹 How It Works in a Playbook

By default, when you run a playbook, Ansible runs the setup module at the beginning — unless you turn it off.

Here’s an example of calling it manually:

- name: Gather system facts
  hosts: all
  tasks:
    - name: Get all facts
      setup:

You can also filter facts to get only what you need, like:

- name: Get only network-related facts
  setup:
    filter: "ansible_eth*"

🔹 Summary
Module Name	Purpose
setup	Gathers system facts (like OS, IP, CPU, memory, etc.)


To save the information in files
ansible all -m setup --tree /file-path/to/file-name

to filter information 
ansible all -m setup -a 'filter=ansible_all_ipv6_addresses'
ansible all -m setup -a 'filter=ansible_architecture'
ansible all -m setup -a 'filter=ansible_bios_version'
ansible all -m setup -a 'filter=ansible_default_ipv4'
ansible all -m setup -a 'filter=ansible_distribution'
ansible all -m setup -a 'filter=ansible_dns'
ansible all -m setup -a 'filter=ansible_kernel'
ansible all -m setup -a 'filter=ansible_mounts'
ansible all -m setup -a 'filter=ansible_python_version'
ansible all -m setup -a 'filter=ansible_virtualization_type'

ansible all -m setup -a 'filter=ansible_mounts' | grep -i device
ansible all -m setup -a 'filter=ansible_mounts' | grep -i mount
ansible all -m setup -a 'filter=ansible_mounts' | grep -i fstype

########################################################

lec 38
Ansible facts part-2 

Custom facts
🔹 What Are Custom Facts?

Custom facts are user-defined pieces of information that Ansible can read just like regular facts. These can be used to store anything you want — like:

    Environment type (dev, test, prod)

    Special config values

    Software versions

    Anything specific to your setup

Note: whenever we run playbook it automatically gather facts before task execution . 
We can disable gather facts below hosts define "gather_facts: false OR gather_facts: no "


🔹 How to Create Custom Facts

Ansible reads custom facts from files in:

/etc/ansible/facts.d/

You can create a custom .fact file in JSON, INI, or executable script format.
✅ Example: JSON Format Custom Fact

Create a file on the managed host (not controller):

sudo mkdir -p /etc/ansible/facts.d
sudo nano /etc/ansible/facts.d/custom_facts.fact

[worker-node-01]
apache = 4.5.6
kernel = 3.2
disk = 10GB
RAM = 32 GB

ansible all -m setup -a 'filter=ansible_local'
ansible all -m setup -a 'filter=ansible_local' | grep -i kernel



Content (JSON):

{
  "env": "production",
  "owner": "DevOps Team"
}

Make sure it's readable:

sudo chmod +x /etc/ansible/facts.d/custom_facts.fact

🔹 Accessing Custom Facts in a Playbook

- name: Show custom facts
  hosts: all
  tasks:
    - name: Print custom environment
      debug:
        msg: "This is the {{ ansible_local.custom_facts.env }} environment"

Output:

This is the production environment

🔹 Summary
Step	What to Do
1️⃣	Create folder: /etc/ansible/facts.d/
2️⃣	Add a .fact file in JSON/INI/script
3️⃣	Access it in playbooks using ansible_local.<fact_file>.<key>


########################################################
lec 39 
Ansible Conditional Statemaent
In Ansible, conditional statements are typically used to control task execution based on variables, facts, or the outcome of previous tasks. This is mainly done using the when keyword.
✅ Basic conditional using a variable:

- name: Install Nginx if OS is Ubuntu
  apt:
    name: nginx
    state: present
  when: ansible_facts['os_family'] == "Debian"


Use Case: Installing packages based on OS type
Other common use cases:


    ✅ Run a task only if a file exists

    ✅ Skip tasks for certain hosts

    ✅ Restart a service only if the config changed

    ✅ Run cleanup tasks only if a flag is set

    ✅ Set different values or files based on environment (dev, test, prod)

In Ansible, conditional statements mostly revolve around the when keyword, but you can use it in different ways depending on the type of condition you’re checking.

Here are the main types of conditional statements in Ansible:
🔹 1. Boolean conditions

Check if a variable is true or false.

when: my_flag == true

Or shorter:

when: my_flag

🔹 2. String comparison

Compare text values.

when: my_var == "production"

🔹 3. Numeric comparison

Compare numbers (equal to, less than, greater than, etc.)

when: some_number > 10
when: some_value | int <= 5

🔹 4. List membership

Check if a value is in a list.

when: "'nginx' in installed_packages"

🔹 5. File or command result (using registered variables)

Check results from earlier tasks.

- name: Check if file exists
  stat:
    path: /etc/myconfig.conf
  register: myfile

- name: Run only if file exists
  debug:
    msg: "File found!"
  when: myfile.stat.exists

🔹 6. Multiple conditions (AND/OR)

Run a task if all or any conditions are met.

# AND condition
when:
  - env == "production"
  - app_installed == true

# OR condition
when: env == "dev" or env == "test"

🔹 7. Negation (NOT)

Run a task unless a condition is true.

when: my_var != "test"

Or:

when: not my_flag

🔹 8. Using Ansible facts

Facts about the system (like OS, IP, etc.)

when: ansible_facts['distribution'] == "Ubuntu"

Each type lets you control when and how tasks run, making your playbooks smarter and more dynamic.

lab

Conditional Operator
==
!<
<
>
<=
>=
and 
or

By default setup module is running at background in from there we fetch the information . 

eg. 01
vim equal-to-operator.yaml
- name: Conditional statement
  hosts: dev
  tasks:
     - name: "install httpd if distro ubuntu"
        yum:
          name: httpd
          state: installed
        when: ansible_distribution == "CentOS"
        when: ansible_distribution_major_version == "7"  
        when: ansible_kernel == "3.10.0.-1062.el7.x86_64" # it give higher preference to last define value. 


 ansible-playbook conditional.yaml

#####################################################

lec 40
Ansible Conditionals
Not Equal to operator (!=)

vim not-equal-to-operator.yaml
- name: "NOT equal to operator"
  hosts: dev
  tasks:
     - name: "install httpd if distro ubuntu"
        yum:
          name: httpd
          state: installed
        when: ansible_distribution != "CentOS"


#######################################################
lec 41
Ansible Conditionals
Less than operator (<)

vim less-than-operator.yaml
- name: Less than operator
  hosts: dev
  tasks:
     - name: "install httpd if distro ubuntu"
        yum:
          name: httpd
          state: installed
        when: ansible_distribution_major_version < "7"  

It will run all machine where all version less than 7  like 6,5,4,3,..

Less than equal to  operator (<=)

vim less-than-equal-to-operator.yaml
- name: Less than equal to operator
  hosts: dev
  tasks:
     - name: "install httpd if distro ubuntu"
        yum:
          name: httpd
          state: installed
        when: ansible_distribution_major_version <= "7"  

It will run all machine where all version less than 7  like including 7, because less than equal to operator is defined. 

Greater than operator (>)

vim greater-than-operator.yaml
- name: Greater than operator
  hosts: dev
  tasks:
     - name: "install httpd if distro ubuntu"
        yum:
          name: httpd
          state: installed
        when: ansible_distribution_major_version > "7"  

It will run all machine where all version greater than 7  like 8,9,10..

Greater than and equal operator (<)

vim greater-than-equal-operator.yaml
- name: Greater than Equal operator
  hosts: dev
  tasks:
     - name: "install httpd if distro ubuntu"
        yum:
          name: httpd
          state: installed
        when: ansible_distribution_major_version >= "7"  

It will run all machine where all version greater than 7  like including 7. because greater than equal to operator is defined. 

########################################################

lec 42
Ansible Conditionals  and Or opertor
Note:
In And operator both condition must be true then it will execute. 

 Operator (and)

vim and-operator.yaml
- name: Add operator
  hosts: dev
  tasks:
    - name:  "install httpd "
      yum: 
         name: httpd
         state: installed
      when: ansible_distribution_major_version == "7" and ansible_distribution == "CentOS"

ansible-playbook  and-operator.yaml



Or operator 

In or operator any of the condition match it will exeute. 

vim or-operator.yaml
- name: "OR operator"
  hosts: dev
  tasks:
    - name: "Installing httpd"
      yum:
          name: httpd
          state: installed
      when: (ansible_distribution_majr_version == "7"  or ansible_distribution == "CentOS") 

And OR operator 
vim and-or-operator.yaml
- name: "AND - OR operator"
  hosts: dev
  tasks:
    - name: "Installing httpd"
      yum:
          name: httpd
          state: installed
      when: (ansible_distribution_majr_version == "7"  or ansible_distribution == "CentOS") and (ansible_distribution_majr_version == "23"  or ansible_distribution == "Ubuntu")

###########################################################

lec 43
Ansible Condition 
Gather facts from the worker nodes
Stat module 
	Retrieves facts for a file similar to the Linux/Unix 'stat' command. For Windows targets, us the [ansible.windows.win_stat] module instead. 
The `stat` module in Ansible is used to retrieve file or directory metadata on a target hosts. 
It's useful when you want to check if a file or directory exists, get permission stamps, or other attributes before performing an action. 

Check doc
ansible-doc stat


vim stat.yaml
- name: Stat module to retrieve file or dir metadata on target hosts
  hosts: web
  vars:
    myfile: /tmp/test-file.txt

  tasks:
    - name: "Check if file {{ myfile }} exists"
      stat:
        path: "{{ myfile }}"
      register: file_stat

    - name: Display file stat output using debug
      debug:
        var: file_stat

[root@worker-01 ansible]# ansible-playbook stat.yaml

PLAY [Stat module to retrieve file or dir metadata on target hosts] ********************

TASK [Gathering Facts] *****************************************************************
ok: [192.168.95.130]

TASK [Check if file /tmp/test-file.txt exists] *****************************************
ok: [192.168.95.130]

TASK [Display file stat output using debug] ********************************************
ok: [192.168.95.130] => {
    "file_stat": {
        "changed": false,
        "failed": false,
        "stat": {
            "atime": 1744734950.634439,
            "attr_flags": "",
            "attributes": [],
            "block_size": 4096,
            "blocks": 0,
            "charset": "binary",
            "checksum": "da39a3ee5e6b4b0d3255bfef95601890afd80709",
            "ctime": 1744734950.634439,
            "dev": 64768,
            "device_type": 0,
            "executable": false,
            "exists": true,
            "gid": 0,
            "gr_name": "root",
            "inode": 17424626,
            "isblk": false,
            "ischr": false,
            "isdir": false,
            "isfifo": false,
            "isgid": false,
            "islnk": false,
            "isreg": true,
            "issock": false,
            "isuid": false,
            "mimetype": "inode/x-empty",
            "mode": "0644",
            "mtime": 1744734950.634439,
            "nlink": 1,
            "path": "/tmp/test-file.txt",
            "pw_name": "root",
            "readable": true,
            "rgrp": true,
            "roth": true,
            "rusr": true,
            "size": 0,
            "uid": 0,
            "version": "3391813796",
            "wgrp": false,
            "woth": false,
            "writeable": true,
            "wusr": true,
            "xgrp": false,
            "xoth": false,
            "xusr": false
        }
    }
}

PLAY RECAP *****************************************************************************
192.168.95.130             : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    

Stat with conditions
eg. 
stat.yaml
- name: Stat module to retrieve file or dir metadata on target hosts
  hosts: web
  gather_facts: false
  vars:
    myfile: /tmp/test-file.txt

  tasks:
    - name: "Check if file {{ myfile }} exists"
      stat:
        path: "{{ myfile }}"
      register: file_stat

    - name: Display file stat output using debug
      debug:
        var: file_stat

    - name: "Append content if file exists {{ myfile }} "
      copy:
        content: "Appending content inside file.."
        dest: "{{ myfile }}"
      when: file_stat.stat.exists == true

[root@worker-01 ansible]# ansible-playbook stat.yaml

PLAY [Stat module to retrieve file or dir metadata on target hosts] ********************

TASK [Check if file /tmp/test-file.txt exists] *****************************************
ok: [192.168.95.130]

TASK [Display file stat output using debug] ********************************************
ok: [192.168.95.130] => {
    "file_stat": {
        "ansible_facts": {
            "discovered_interpreter_python": "/usr/bin/python3"
        },
        "changed": false,
        "failed": false,
        "stat": {
            "atime": 1744734961.325545,
            "attr_flags": "",
            "attributes": [],
            "block_size": 4096,
            "blocks": 0,
            "charset": "binary",
            "checksum": "da39a3ee5e6b4b0d3255bfef95601890afd80709",
            "ctime": 1744734950.634439,
            "dev": 64768,
            "device_type": 0,
            "executable": false,
            "exists": true,
            "gid": 0,
            "gr_name": "root",
            "inode": 17424626,
            "isblk": false,
            "ischr": false,
            "isdir": false,
            "isfifo": false,
            "isgid": false,
            "islnk": false,
            "isreg": true,
            "issock": false,
            "isuid": false,
            "mimetype": "inode/x-empty",
            "mode": "0644",
            "mtime": 1744734950.634439,
            "nlink": 1,
            "path": "/tmp/test-file.txt",
            "pw_name": "root",
            "readable": true,
            "rgrp": true,
            "roth": true,
            "rusr": true,
            "size": 0,
            "uid": 0,
            "version": "3391813796",
            "wgrp": false,
            "woth": false,
            "writeable": true,
            "wusr": true,
            "xgrp": false,
            "xoth": false,
            "xusr": false
        }
    }
}

TASK [Append content if file exists /tmp/test-file.txt] ********************************
changed: [192.168.95.130]

PLAY RECAP *****************************************************************************
192.168.95.130             : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

[root@worker-01 ansible]# ansible web -m shell -a "cat /tmp/test-file.txt"
192.168.95.130 | CHANGED | rc=0 >>
Appending content inside file..



###################################################################
lec 44 
Ansible Conditionals 

vim conditionals.yaml
- name: Conditional Advance topic eg.
  hosts: web
  gather_facts: false
  tasks:
    - name: check sshd sevice is active
      command: systemctl is-active sshd
      register: report

    - name: debug command
      debug:
        var: report
[root@worker-01 ansible]# ansible-playbook conditionals.yaml

PLAY [Conditional Advance topic eg.] ***************************************************

TASK [check sshd sevice is active] *****************************************************
changed: [192.168.95.130]

TASK [debug command] *******************************************************************
ok: [192.168.95.130] => {
    "report": {
        "ansible_facts": {
            "discovered_interpreter_python": "/usr/bin/python3"
        },
        "changed": true,
        "cmd": [
            "systemctl",
            "is-active",
            "sshd"
        ],
        "delta": "0:00:00.009243",
        "end": "2025-04-16 19:44:10.975219",
        "failed": false,
        "msg": "",
        "rc": 0,
        "start": "2025-04-16 19:44:10.965976",
        "stderr": "",
        "stderr_lines": [],
        "stdout": "active",
        "stdout_lines": [
            "active"
        ]
    }
}

PLAY RECAP *****************************************************************************
192.168.95.130             : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

Add condition in and tasks. 
vim conditionals.yaml
- name: Conditional Advance topic eg.
  hosts: web
  gather_facts: false
  tasks:
    - name: check sshd sevice is active
      command: systemctl is-active sshd
      register: report

    - name: debug command
      debug:
        var: report

    - name: httpd package install
      yum:
        name: httpd
        state: latest
      when: report.stdout == "active"
[root@worker-01 ansible]# ansible-playbook conditionals.yaml

PLAY [Conditional Advance topic eg.] ***************************************************

TASK [check sshd sevice is active] *****************************************************
changed: [192.168.95.130]

TASK [debug command] *******************************************************************
ok: [192.168.95.130] => {
    "report": {
        "ansible_facts": {
            "discovered_interpreter_python": "/usr/bin/python3"
        },
        "changed": true,
        "cmd": [
            "systemctl",
            "is-active",
            "sshd"
        ],
        "delta": "0:00:00.008519",
        "end": "2025-04-16 19:55:23.098894",
        "failed": false,
        "msg": "",
        "rc": 0,
        "start": "2025-04-16 19:55:23.090375",
        "stderr": "",
        "stderr_lines": [],
        "stdout": "active",
        "stdout_lines": [
            "active"
        ]
    }
}

TASK [httpd package install] ***********************************************************
changed: [192.168.95.130]

PLAY RECAP *****************************************************************************
192.168.95.130             : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

ansible web -m command -a "dnf list httpd"
192.168.95.130 | CHANGED | rc=0 >>
Updating Subscription Management repositories.
Last metadata expiration check: 0:09:08 ago on Wednesday 16 April 2025 07:48:21 PM.
Installed Packages
httpd.x86_64         2.4.62-1.el9_5.2          @rhel-9-for-x86_64-appstream-rpms

#####################################################################

Lec 45

Ansible Notify Handlers
In Ansible, handlers are special tasks that only run when notified by another task. This is usually used for things like restarting services only if something changed (eg. a config file was updated). 


vim handlers.yaml

- name: Deny SSH Access for User
  hosts: web
  gather_facts: false
  vars:
    myfile: /etc/ssh/sshd_config
  tasks:
    - name: "Add DenyUsers directive for harry"
      lineinfile:
        path: "{{ myfile }}"
        line: "DenyUsers harry"
        insertafter: EOF
        state: present
      notify: restart sshd

  handlers:
    - name: restart sshd
      service:
        name: sshd
        state: restarted


[root@worker-01 ansible]# ansible-playbook handlers.yaml -vv
ansible-playbook [core 2.14.17]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.9/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible-playbook
  python version = 3.9.21 (main, Dec  5 2024, 00:00:00) [GCC 11.5.0 20240719 (Red Hat 11.5.0-2)] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
Using /etc/ansible/ansible.cfg as config file
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: handlers.yaml *************************************************************
1 plays in handlers.yaml

PLAY [Deny SSH Access for User] *****************************************************

TASK [Add DenyUsers directive for harry] ********************************************
task path: /root/ansible/handlers.yaml:7
NOTIFIED HANDLER restart sshd for 192.168.95.130
changed: [192.168.95.130] => {"ansible_facts": {"discovered_interpreter_python": "/usr/bin/python3"}, "backup": "", "changed": true, "msg": "line added"}

RUNNING HANDLER [restart sshd] ******************************************************
task path: /root/ansible/handlers.yaml:16
changed: [192.168.95.130] => {"changed": true, "name": "sshd", "state": "started", "status": {"AccessSELinuxContext": "system_u:object_r:sshd_unit_file_t:s0", "ActiveEnterTimestamp": "Fri 2025-04-18 11:35:55 IST", "ActiveEnterTimestampMonotonic": "1823483078", "ActiveExitTimestamp": "Fri 2025-04-18 11:35:55 IST", "ActiveExitTimestampMonotonic": "1823466796", "ActiveState": "active", "After": "sshd-keygen.target systemd-journald.socket basic.target system.slice sysinit.target network.target", "AllowIsolate": "no", "AssertResult": "yes", "AssertTimestamp": "Fri 2025-04-18 11:35:55 IST", "AssertTimestampMonotonic": "1823469299", "Before": "multi-user.target shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "[not set]", "CPUAccounting": "yes", "CPUAffinityFromNUMA": "no", "CPUQuotaPerSecUSec": "infinity", "CPUQuotaPeriodUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "[not set]", "CPUUsageNSec": "63588000", "CPUWeight": "[not set]", "CacheDirectoryMode": "0755", "CanFreeze": "yes", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore", "CleanResult": "success", "CollectMode": "inactive", "ConditionResult": "yes", "ConditionTimestamp": "Fri 2025-04-18 11:35:55 IST", "ConditionTimestampMonotonic": "1823469299", "ConfigurationDirectoryMode": "0755", "Conflicts": "shutdown.target", "ConsistsOf": "sshd-keygen.target", "ControlGroup": "/system.slice/sshd.service", "ControlGroupId": "14293", "ControlPID": "0", "CoredumpFilter": "0x33", "DefaultDependencies": "yes", "DefaultMemoryLow": "0", "DefaultMemoryMin": "0", "Delegate": "no", "Description": "OpenSSH server daemon", "DevicePolicy": "auto", "Documentation": "\"man:sshd(8)\" \"man:sshd_config(5)\"", "DynamicUser": "no", "EffectiveCPUs": "0-3", "EffectiveMemoryNodes": "0", "EnvironmentFiles": "/etc/sysconfig/sshd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "9555", "ExecMainStartTimestamp": "Fri 2025-04-18 11:35:55 IST", "ExecMainStartTimestampMonotonic": "1823474235", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecReloadEx": "{ path=/bin/kill ; argv[]=/bin/kill -HUP $MAINPID ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/sbin/sshd ; argv[]=/usr/sbin/sshd -D $OPTIONS ; ignore_errors=no ; start_time=[Fri 2025-04-18 11:35:55 IST] ; stop_time=[n/a] ; pid=9555 ; code=(null) ; status=0/0 }", "ExecStartEx": "{ path=/usr/sbin/sshd ; argv[]=/usr/sbin/sshd -D $OPTIONS ; flags= ; start_time=[Fri 2025-04-18 11:35:55 IST] ; stop_time=[n/a] ; pid=9555 ; code=(null) ; status=0/0 }", "ExitType": "main", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FinalKillSignal": "9", "FragmentPath": "/usr/lib/systemd/system/sshd.service", "FreezerState": "running", "GID": "[not set]", "GuessMainPID": "yes", "IOAccounting": "no", "IOReadBytes": "18446744073709551615", "IOReadOperations": "18446744073709551615", "IOSchedulingClass": "2", "IOSchedulingPriority": "4", "IOWeight": "[not set]", "IOWriteBytes": "18446744073709551615", "IOWriteOperations": "18446744073709551615", "IPAccounting": "no", "IPEgressBytes": "[no data]", "IPEgressPackets": "[no data]", "IPIngressBytes": "[no data]", "IPIngressPackets": "[no data]", "Id": "sshd.service", "IgnoreOnIsolate": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestamp": "Fri 2025-04-18 11:35:55 IST", "InactiveEnterTimestampMonotonic": "1823468312", "InactiveExitTimestamp": "Fri 2025-04-18 11:35:55 IST", "InactiveExitTimestampMonotonic": "1823474640", "InvocationID": "46024a4786004ec9b07ddc645627092d", "JobRunningTimeoutUSec": "infinity", "JobTimeoutAction": "none", "JobTimeoutUSec": "infinity", "KeyringMode": "private", "KillMode": "process", "KillSignal": "15", "LimitAS": "infinity", "LimitASSoft": "infinity", "LimitCORE": "infinity", "LimitCORESoft": "infinity", "LimitCPU": "infinity", "LimitCPUSoft": "infinity", "LimitDATA": "infinity", "LimitDATASoft": "infinity", "LimitFSIZE": "infinity", "LimitFSIZESoft": "infinity", "LimitLOCKS": "infinity", "LimitLOCKSSoft": "infinity", "LimitMEMLOCK": "8388608", "LimitMEMLOCKSoft": "8388608", "LimitMSGQUEUE": "819200", "LimitMSGQUEUESoft": "819200", "LimitNICE": "0", "LimitNICESoft": "0", "LimitNOFILE": "524288", "LimitNOFILESoft": "1024", "LimitNPROC": "14255", "LimitNPROCSoft": "14255", "LimitRSS": "infinity", "LimitRSSSoft": "infinity", "LimitRTPRIO": "0", "LimitRTPRIOSoft": "0", "LimitRTTIME": "infinity", "LimitRTTIMESoft": "infinity", "LimitSIGPENDING": "14255", "LimitSIGPENDINGSoft": "14255", "LimitSTACK": "infinity", "LimitSTACKSoft": "8388608", "LoadState": "loaded", "LockPersonality": "no", "LogLevelMax": "-1", "LogRateLimitBurst": "0", "LogRateLimitIntervalUSec": "0", "LogsDirectoryMode": "0755", "MainPID": "9555", "ManagedOOMMemoryPressure": "auto", "ManagedOOMMemoryPressureLimit": "0", "ManagedOOMPreference": "none", "ManagedOOMSwap": "auto", "MemoryAccounting": "yes", "MemoryAvailable": "infinity", "MemoryCurrent": "3633152", "MemoryDenyWriteExecute": "no", "MemoryHigh": "infinity", "MemoryLimit": "infinity", "MemoryLow": "0", "MemoryMax": "infinity", "MemoryMin": "0", "MemorySwapMax": "infinity", "MountAPIVFS": "no", "NFileDescriptorStore": "0", "NRestarts": "0", "NUMAPolicy": "n/a", "Names": "sshd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMPolicy": "stop", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "OnSuccessJobMode": "fail", "Perpetual": "no", "PrivateDevices": "no", "PrivateIPC": "no", "PrivateMounts": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "PrivateUsers": "no", "ProcSubset": "all", "ProtectClock": "no", "ProtectControlGroups": "no", "ProtectHome": "no", "ProtectHostname": "no", "ProtectKernelLogs": "no", "ProtectKernelModules": "no", "ProtectKernelTunables": "no", "ProtectProc": "default", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "ReloadResult": "success", "ReloadSignal": "1", "RemainAfterExit": "no", "RemoveIPC": "no", "Requires": "system.slice sysinit.target", "Restart": "on-failure", "RestartKillSignal": "15", "RestartUSec": "42s", "RestrictNamespaces": "no", "RestrictRealtime": "no", "RestrictSUIDSGID": "no", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "RuntimeDirectoryPreserve": "no", "RuntimeMaxUSec": "infinity", "RuntimeRandomizedExtraUSec": "0", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitIntervalUSec": "10s", "StartupBlockIOWeight": "[not set]", "StartupCPUShares": "[not set]", "StartupCPUWeight": "[not set]", "StartupIOWeight": "[not set]", "StateChangeTimestamp": "Fri 2025-04-18 11:35:55 IST", "StateChangeTimestampMonotonic": "1823483078", "StateDirectoryMode": "0755", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SuccessAction": "none", "SyslogFacility": "3", "SyslogLevel": "6", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "2147483646", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "yes", "TasksCurrent": "1", "TasksMax": "22808", "TimeoutAbortUSec": "1min 30s", "TimeoutCleanUSec": "infinity", "TimeoutStartFailureMode": "terminate", "TimeoutStartUSec": "1min 30s", "TimeoutStopFailureMode": "terminate", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "notify", "UID": "[not set]", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "UtmpMode": "init", "WantedBy": "multi-user.target", "Wants": "sshd-keygen.target", "WatchdogSignal": "6", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}

PLAY RECAP **************************************************************************
192.168.95.130             : ok=2    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

[root@worker-01 ansible]# ansible web -m command -a "tail -2 /etc/ssh/sshd_config"
192.168.95.130 | CHANGED | rc=0 >>
#       ForceCommand cvs server
DenyUsers harry


If the above playbook doesn't work then firstly execute this playbook

- name: Notify Handlers
  hosts: web
  gather_facts: false
  vars:
    myfile: /etc/ssh/sshd_config
  tasks:
    - name: "Validate SSHD Config"
      command: sshd -t
      register: result
      ignore_errors: true

    - name: "Debug Validation Output"
      debug:
        var: result.stdout

  handlers:
    - name: restart sshd
      service:
        name: sshd
        state: restarted

eg. 2
handlers-2.yaml
- name: Deny SSH Access for User
  hosts: web
  gather_facts: false
  vars:
    myfile: /etc/ssh/sshd_config
    copyfile: /etc/passwd
  tasks:
    - name: "Add DenyUsers directive for harry"
      lineinfile:
        path: "{{ myfile }}"
        line: "DenyUsers harry"
        insertafter: EOF
        state: present
      notify:
        - restart sshd
        - install httpd

    - name: "Copy file {{ copyfile }} "
      copy:
        src: "{{ copyfile }}"
        dest: /tmp

  handlers:
    - name: restart sshd
      service:
        name: sshd
        state: restarted

    - name: install httpd
      yum:
        name: httpd
        state: installed
[root@worker-01 ansible]# ansible-playbook handlers-2.yaml

PLAY [Deny SSH Access for User] *****************************************************

TASK [Add DenyUsers directive for harry] ********************************************
changed: [192.168.95.130]

TASK [Copy file /etc/passwd] ********************************************************
changed: [192.168.95.130]

RUNNING HANDLER [restart sshd] ******************************************************
changed: [192.168.95.130]

RUNNING HANDLER [install httpd] *****************************************************
changed: [192.168.95.130]

PLAY RECAP **************************************************************************
192.168.95.130             : ok=4    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

[root@worker-01 ansible]# ansible web -m raw -a 'tail -2 /etc/ssh/sshd_config; ls -l /tmp/passwd; systemctl is-active sshd; yum list installed httpd; systemctl is-active httpd'

192.168.95.130 | FAILED | rc=3 >>
#       ForceCommand cvs server
DenyUsers harry
-rw-r--r--. 1 root root 2039 Apr 18 12:02 /tmp/passwd
active
Updating Subscription Management repositories.
Installed Packages
httpd.x86_64         2.4.62-1.el9_5.2          @rhel-9-for-x86_64-appstream-rpms
inactive
Shared connection to 192.168.95.130 closed.
non-zero return code

# harry user try to login [prompt-correct password]
ssh harry@192.168.95.130
harry@192.168.95.130's password:
Permission denied, please try again.
harry@192.168.95.130's password:
Permission denied, please try again.
harry@192.168.95.130's password:
harry@192.168.95.130: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).

####################################################################################

lec 46 
Ansible Tag

Ansible Tag is a way to organize and control which parts of your automation tasks should run in Ansible . 

When you use tags, you can label certain parts of your Ansible playbook ( like a tasks or a group of tasks) with specific name (tags). Then, when you run your playbook , you can tell Ansible to only run the tasks that have a specific tag, instead of running the whole playbook. 

Syntax to define tags in playbook 

tasks:
  - name: install httpd package
    yum: 
      name: httpd 
      state: installed
    tags: dev-team
  
  - name: create file
    file:
       path: /tmp/test-file.txt
       state: touch
    tags: test-team

To run dev-team tag
ansible-playbook playbook.yaml --tags dev-team 

eg. 
vim tag.yaml
- name: Ansible Tag
  hosts: web
  tasks:
    - name: copy file
      copy:
        src: /etc/passwd
        dest: /tmp
      tags: dev-team

    - name: create directory
      file:
        path: /tmp/test-dir
        state: directory
      tags: test-team

    - name: install httpd package
      yum:
        name: httpd
        state: installed
      tags: prod-team

    - name: service start & enable httpd
      service:
        name: httpd
        state: started
        enabled: yes
      tags: admin-team
[root@worker-01 ansible]# ansible-playbook tag.yaml --tag=dev-team

PLAY [Ansible Tag] *****************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************
ok: [192.168.95.130]

TASK [copy file] *******************************************************************************************************
changed: [192.168.95.130]

PLAY RECAP *************************************************************************************************************
192.168.95.130             : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

[root@worker-01 ansible]# ansible web -m command -a "ls -lh /tmp/"
192.168.95.130 | CHANGED | rc=0 >>
total 4.0K
drwx------. 2 root root   56 Apr 19 21:30 ansible_ansible.legacy.command_payload_e_a2ky_v
-rw-r--r--. 1 root root 2.0K Apr 19 21:29 passwd


To run an Ansible playbook with multiple tags, you can simply separate the tags with a comma, without spaces between them.

[root@worker-01 ansible]# ansible-playbook tag.yaml --tag="dev-team,test-team"

PLAY [Ansible Tag] ************************************************************************

TASK [Gathering Facts] ********************************************************************
ok: [192.168.95.130]

TASK [copy file] **************************************************************************
changed: [192.168.95.130]

TASK [create directory] *******************************************************************
changed: [192.168.95.130]

PLAY RECAP ********************************************************************************
192.168.95.130             : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


--skip-tag
it will run all tasks defined in playbook accept --skip-tag="tag-name-defined"

Let's dev-team  tag in the same playbook  tag.yaml 

[root@worker-01 ansible]# ansible-playbook tag.yaml --skip-tag=dev-team

PLAY [Ansible Tag] *****************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************
ok: [192.168.95.130]

TASK [create directory] ************************************************************************************************
changed: [192.168.95.130]

TASK [install httpd package] *******************************************************************************************
changed: [192.168.95.130]

TASK [service start & enable httpd] ************************************************************************************
changed: [192.168.95.130]

PLAY RECAP *************************************************************************************************************
192.168.95.130             : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

[root@worker-01 ansible]# ansible web -m raw -a "ls -lh /tmp/; dnf list installed httpd; systemctl is-active httpd"
192.168.95.130 | CHANGED | rc=0 >>
total 4.0K
-rw-r--r--. 1 root root 2.0K Apr 19 21:29 passwd
drwx------. 3 root root   17 Apr 19 21:33 systemd-private-4116c151def64e9ebf5b04c9a2d6e6fc-httpd.service-k7aj62
drwxr-xr-x. 2 root root    6 Apr 19 21:33 test-dir
Updating Subscription Management repositories.
Installed Packages
httpd.x86_64         2.4.62-1.el9_5.2          @rhel-9-for-x86_64-appstream-rpms
active
Shared connection to 192.168.95.130 closed.


To Skip multiple tags tasks
[root@worker-01 ansible]# ansible-playbook tag.yaml --skip-tag="prod-team,admin-team"

PLAY [Ansible Tag] ************************************************************************

TASK [Gathering Facts] ********************************************************************
ok: [192.168.95.130]

TASK [copy file] **************************************************************************
changed: [192.168.95.130]

TASK [create directory] *******************************************************************
changed: [192.168.95.130]

PLAY RECAP ********************************************************************************
192.168.95.130             : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

Running multiple tags but excluding some:
If you want to run tasks with web and db, but exclude tasks tagged db, you could combine --tags and --skip-tags:

ansible-playbook playbook.yaml --tags="web" --skip-tags="db"

     

#################################################################
lec 47 
Ansible Ignore errors 

In Ansible , the ignore_errors directive allows you to continue running a playbook even if a particular tasks fails. But default, when a tasks fails, Ansible stop executing the remaning tasks. However if you want Ansible to proceed with rest of the tasks, even when one fails , you can use ignore_errors: yes

When to use ignore_errors:
When you know a task might fail, but you still want the playbook to continue (like when installing packages that may not be available on every host).

When a failure in one task is not critical and doesn't impact the overall result of the playbook.

eg. 
vim ignore_error.yaml
- name: ignore_errors
  hosts: web
  gather_facts: false
  tasks:
    - name: copy file
      copy:
        src: /etc/group1  # create manual error, no such file exists
        dest: /tmp
      ignore_errors: yes

    - name: create directory
      file:
        path: /tmp/test-dir
        state: directory

    - name: install package httpd
      yum:
        name: httpd
        state: installed

    - name: service start & enable httpd
      service:
        name: httpd
        state: started
        enabled: yes


[root@worker-01 ansible]# ansible-playbook ignore_error.yaml

PLAY [ignore_errors] **********************************************************************

TASK [copy file] **************************************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
fatal: [192.168.95.130]: FAILED! => {"changed": false, "msg": "Could not find or access '/etc/group1' on the Ansible Controller.\nIf you are using a module and expect the file to exist on the remote, see the remote_src option"}
...ignoring

TASK [create directory] *******************************************************************
changed: [192.168.95.130]

TASK [install package httpd] **************************************************************
ok: [192.168.95.130]

TASK [service start & enable httpd] *******************************************************
ok: [192.168.95.130]

PLAY RECAP ********************************************************************************
192.168.95.130             : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=1


[root@worker-01 ansible]# ansible web -m raw -a "ls -lh /tmp/; dnf list installed httpd; systemctl is-active httpd"
192.168.95.130 | CHANGED | rc=0 >>
total 0
drwxr-xr-x. 2 root root 6 Apr 19 21:56 test-dir
Updating Subscription Management repositories.
Installed Packages
httpd.x86_64         2.4.62-1.el9_5.2          @rhel-9-for-x86_64-appstream-rpms
active
Shared connection to 192.168.95.130 closed.

###############################################################################################

